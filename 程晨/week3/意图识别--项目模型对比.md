意图识别模型：

一.bert 模型：

优点： 1.能够在上下文语境中理解词汇。 2.能够去应对未处理的新表达。 3.微调的数据相对较少。

缺点： 1.训练成本高。 2.需要一定量的标注数据进行微调。 3.决策过程的可解释性差。 4.部署比较复杂，模型比较大。

适用场景： 1.对准确率要求高的复杂场景。 2.意图种类多，表达方式多样的系统。 3.具有一定标注数据的业务。

二.使用正则表达式表达：

优点： 1.规则库可控，准确可行。 2.不需要模型学习成本。 3.计算速度快。 4.匹配的原因清晰。

缺点： 1.泛化能力差，没办法去处理未见过的新表达方式。 2.虽然不用模型学习，但是需要人工去编写和持续的更行。 3.同义词没法处理。eg：今天气死我了。这明显跟天气这个词没关系。中文的歧义难以去处理。

适用场景： 1.固定格式的文本（订单韩，指令） 2.作为初筛的过滤器，拦截高置信度的意图 3.对准确度要求极高的关键指令

三.提示词工程结合大语言模型：

优点： 1.不需要训练，不需要标注数据和微调，开箱即用。 2.比较灵活，能够轻松应对新意图、多意图、复杂意图。 3.潜力巨大，能够利用LLM的海量知识进行推理。

缺点： 1.成本较高，调用api费用高，延迟也高 2.敏感数据的处理需要谨慎考虑。 3.提示词的设置需要经验技巧。

适用场景： 1.快速原型验证和概念验证。 2.意图比较复杂、多变的场景。 3.没有任何标注数据的冷启动场景。

四.TF-IDF+传统模型：

优点： 1.无需标注大数据，学习成本比深度学习模型小。 2.能够去分析特征词的重要性。 3.训练和预测速度较快。 4.流程简单稳定。

缺点： 1.不像bert和大模型一样能理解词序、上下文和语义。 2.向量维度高且稀疏，性能有瓶颈。 3.中文分词的效果对模型影响极大。 4.对新词难以处理。

适用场景： 1.小规模的数据集。 2.计算资源受限的设备 3.作为效果验证的基线模型。
